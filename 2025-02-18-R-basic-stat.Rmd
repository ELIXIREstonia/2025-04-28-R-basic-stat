---
title: "2025-02-18-R-basic-stat"
author: "Marilin Moor"
date: "2025-02-18"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction to statistics in R course

```{r}
# imports 
library(tidyverse)
library(patchwork)
library(dplyr)
library(ISwR) # Introductory Stat w R
library(cluster)
library(ggplot2)
library(ggpubr)
library(rstatix)
library(pheatmap)
# install if not already installed
if(!require(pwr)){
    install.packages("pwr")
    library(pwr)
}
```

### Day 1 

#### **Warm-up: Exploratory data analysis on the `hellung` dataset (from the ISwR library)**

```{r}
# what does this dataset contain?
?hellung
```

```{r}
# let's read in the data 
data(hellung)
```

**Task 1**: Provide minimum two ways to find the mean of glucose.

```{r}

```

**Task 2**: Find the average diameter of cells which were grown with glucose.

```{r}

```

**Task 3**: Show the distributions of all the features of the data set in separate plots and combine them in one frame. Take a look at <https://www.data-to-viz.com/> for plotting inspiration/guidance.

```{r}

```

**Task 4**: Find and visualize if the addition of glucose affects the cell diameter and if cell concentration affects the cell diameters.

```{r}
# correlation function provided here
#cor(hellung$conc, hellung$diameter)
```

#### Example of a power analysis for a two-sample t-test

Theory: <https://zenodo.org/records/14883678/files/Introduction_to_hypothesis_testing_25.pdf?download=1>

Here we have an example of using Lehr's rule to determine the correct sample size for a two-sample t-test.

```{r}
# Step 1: Define Parameters
effect_size <- 0.5  # Medium effect size (Cohen’s d)
population_variance <- 15^2  # Variance (assuming SD = 15)

# Step 2: Lehr's Rule Calculation 
sample_size_one_sided <- (8 * population_variance) / (effect_size^2)
sample_size_two_sided <- (16 * population_variance) / (effect_size^2)

cat("Estimated sample size (one-sided test):", ceiling(sample_size_one_sided), "\n")
cat("Estimated sample size (two-sided test):", ceiling(sample_size_two_sided), "\n")

# Step 3: Power Analysis using pwr.t.test()
power_analysis <- pwr.t.test(d = effect_size, power = 0.8, sig.level = 0.05, type = "two.sample")
cat("Power analysis suggested sample size per group:", ceiling(power_analysis$n), "\n")

# Step 4: Simulate Data and Perform t-test
set.seed(123)  # For reproducibility
n <- ceiling(power_analysis$n)  # Use the computed sample size

group1 <- rnorm(n, mean = 100, sd = sqrt(population_variance))  # Simulated data for group 1
group2 <- rnorm(n, mean = 100 + (effect_size * sqrt(population_variance)), sd = sqrt(population_variance))  # Group 2 with effect size applied

# Perform a statistical t-test
t_test_result <- t.test(group1, group2, var.equal = TRUE)
print(t_test_result)

```

#### **Hypothesis testing**

Theory: <https://zenodo.org/records/14883678/files/Introduction_to_hypothesis_testing_25.pdf?download=1>

Let's now do some hypothesis testing in R!

##### **One-sample t-test (intake dataset)**

i.e. "I have data about A, is there a significant difference in feature X based on the mean of the population of A?"

**Task**: Given the `intake` data set, you wish to test whether there is a significant deviation between the women’s (pre) energy intake and a recommended value of 7725 kJ.

```{r}
?intake
data(intake)
intake
```

```{r}
summary(intake)
```

In order to run a one-sample t-test, we need to check if the assumptions are met:

-   significant outliers: plotting (box plot with data), testing (hint: `identify_outliers()`{style="padding: 0px 1px; border-width: 1px; border-style: solid; border-color: rgb(230, 230, 230) !important; border-image: initial; background-color: rgb(243, 243, 243) !important; font-family: \"Ubuntu Mono\", monospace !important; font-size: 10pt !important;"})

-   normality of the data: plotting (qq plot), testing (hint: `shapiro_test`{style="padding: 0px 1px; border-width: 1px; border-style: solid; border-color: rgb(230, 230, 230) !important; border-image: initial; background-color: rgb(243, 243, 243) !important; font-family: \"Ubuntu Mono\", monospace !important; font-size: 10pt !important; margin-bottom: 0.1em;"})

```{r}
# Assumption: no significant outliers in the data
ggplot(intake, aes(x = "", y = pre)) +
  geom_boxplot(width = 0.5, outlier.shape = NA) +  # Boxplot
  stat_summary(fun = mean, geom = "point", shape = 20, size = 3, color = "red") +  # Mean point
  geom_jitter(width = 0.2, alpha = 0.5) +  # Jitter points
  labs(y = "premenstrual intake", x = NULL) +  # Labels
  theme_minimal() +  # Minimal theme
  theme(axis.text.x = element_blank())  # Remove x-axis text

# identify_outliers() defaults to 
# Q3 + 1.5 * IQR or Q1 - 1.5 * IQR 
# IQR = Q3 - Q1
##########################################################
# TODO: determine if there are any outliers in the dataset
# add your code here

##########################################################

# Assumption: normality
ggplot(intake, aes(sample = pre)) +
  stat_qq() +                       # Q-Q plot - comparing quantiles of two probability distributions
  stat_qq_line(color = "red") +     # Add Q-Q line
  labs(x = "Theoretical Quantiles", y = "Sample Quantiles") +  # Axis labels
  theme_minimal()       

##########################################################
# TODO: test normality using the Shapiro-Wilk test 
# add your code here

##########################################################
```

Now let's test whether there is a significant deviation between the women’s (pre) energy intake and a recommended value of 7725 kJ.

For an alpha level of 0.05, do you reject the null hypothesis? What about for an alpha level of 0.01?

The default `t.test()` assumes that you want a 2-sided test. Use help to find out how you could get a 1-sided test that would be meaningful for the data set, and carry this out. In this case, if alpha level is 0.01, do you reject the null hypothesis?

```{r}

```

##### **Paired t-test (intake dataset continued)**

i.e. "We have data about X at two different time points"

**Task**: Identify if there are significant differences in energy intakes between the pre- and post-menstrual groups.

Let's check if the assumptions for the paired t-test are met:

-   each of the paired measurements must be obtained from the same subject (data collection protocol/help)

-   the measured difference is normally distributed (TODO below)

```{r}

```

Let's do the paired t-test to check for significant differences between the pre and post groups (hint: check the list of arguments for `t.test()`

```{r}

```

##### **Two-sample t-test (energy dataset)**

i.e. "I have data about two subgroups from A: AA and AB, is there a significant difference between feature X in these subgroups?"

**Task**: Identify if there is a significant difference in energy expenditure between the group of lean and group of obese subjects?

```{r}
?energy
data(energy)
energy
```

Checking if the following assumptions are met:

-   energy expenditure data in each group are normally distributed

<!-- -->

-   the variances for two independent groups are equal (hint: `levene_test()`) (F-test is for \<= 2 groups, the levene test compares more groups)

```{r}
# TODO: find if the energy expenditure data in each group are normally distributed

# TODO: ensure that the variances of two independent groups are equal 
```

Now let's test if there is a significant difference between the lean and obese group.

```{r}

```

#### **Multiple testing correction - when and how to use this?**

We have created a list of data sets. Each data set has 30 values generated from normal distributions of different means (1, 0, -1, 0.5).

**Task**: Perform a one-sample t-test (population mean = 0) for each group to test if the mean differs from the population mean.

```{r}
# Set seed for reproducibility
set.seed(123)

# Simulate data for 4 groups - fetching 30 values from a normal distribution
group_A <- rnorm(30, mean = 1, sd = 1)  # Mean 1
group_B <- rnorm(30, mean = 0, sd = 1)  # Mean 0
group_C <- rnorm(30, mean = -1, sd = 1) # Mean -1
group_D <- rnorm(30, mean = 0.5, sd = 1) # Mean 0.5

# Combine into a list
groups <- list(A = group_A, B = group_B, C = group_C, D = group_D)
```

Without multiple testing correction, the p-values are the following:

```{r}
# Conduct t-tests and store p-values
p_values <- sapply(groups, function(group) t.test(group, mu = 0)$p.value)
print(p_values)
```

As we are comparing multiple groups against the same hypothesis, multiple testing correction should be undertaken - please adjust p-values using Bonferroni and Holm correction.

```{r}
# TODO: using `p.adjust()` adjust the double "p_values" using Bonferroni and Holm
##########################################################
# add your code here

##########################################################

# this section will create the correct siginificance values for the Holm correction
num_tests <- length(p_values)
p_order <- order(p_values)
p_sorted <- p_values[p_order]

# Compute Holm thresholds
holm_thresholds <- 0.05 / (num_tests:1)  # 0.05 / (n, n-1, ..., 1)

# Determine significance step-wise
holm_significant_sorted <- rep("No", num_tests)
for (i in 1:num_tests) {
  if (p_sorted[i] < holm_thresholds[i]) {
    holm_significant_sorted[i] <- "Yes"
  } else {
    break  # Once a non-significant value is found, stop marking further ones
  }
}

# Reorder results back to original order
holm_significant <- holm_significant_sorted[order(p_order)]


# Show results
p_values_dataframe <-
  data.frame(
    Group = names(groups),
    Raw_p = p_values,
    Raw_significance = ifelse(p_values < 0.05, "Yes", "No"),
    Bonferroni_p = p_adjusted_bonferroni,
    Bonferroni_significance = ifelse(p_adjusted_bonferroni < (0.05 / no_of_tests), "Yes", "No"),
    Holm_p = p_adjusted_holm,
    Holm_significance = holm_significant
  )

p_values_dataframe
```

#### **Non-parametric test for two samples (air quality data set)**

Theory: <https://zenodo.org/records/14883678/files/Parametric_and_non_parametric_tests_25.pdf?download=1>

**Task**: Perform the Mann-Whitney U Test to check for the significant difference in ozone levels in May and July from the `airquality` data set.

```{r}
?airquality
data(airquality)

# Filter the dataset for May and July
may_july_data <- airquality[airquality$Month %in% c(5, 7), ]

# Create a factor for Month
may_july_data$Month <- factor(may_july_data$Month, labels = c("May", "July"))

# View data structure
str(may_july_data)
```

Let's visualize the apparent differences between the groups and assess the normality (using Shapiro-Wilk normality test) of the ozone data. What do you see?

```{r}
ggplot(may_july_data, aes(x = Month, y = Ozone, fill = factor(Month) ) )+
  geom_boxplot() +
  labs(
    title = "Ozone Levels in May vs July",
    x = "Month",
    y = "Ozone Levels"
  ) +
  theme_minimal()
```

Assess the normality of the ozone data in May and July using Shapiro-Wilk normality test.

```{r}

```

Attempt a log transformation (hint: `log()`) to fix the skewed data and check for normality again.

```{r}

```

Perform the Mann-Whitney U Test (hint: `wilcox_test()`) to check for the difference in ozone levels in May and July. The t-test in the code block is for reference.

```{r}

########## t-test for reference ########## 
t.test(Ozone ~ Month, data = data, exact = FALSE)
```

**This marks the end of Day 1. Congrats! See you next week.**
